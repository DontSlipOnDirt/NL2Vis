# 游쬹vAgent

## 游뗿Introduction

HI! This is the official repository for the paper ["nvAgent: Automated Visualization from Natural Language via Collaborative Agent Workflow"](https://xxxxxxxxxxxxxx).

In this paper, we propose a novel multi-agent framework that integrates preprocessing, *Visualization Query Language* (VQL) generation, and a third stage for output validation and refinement. This comprehensive approach enables *nvAgent* to manage the full complexity of the NL2Vis process, ensuring accuracy and relevance at each step.

<img src="./assets/pipeline_1.jpg" align="middle" width="95%">

## 游꿡Demo

We conduct an web interface to demonstrate how to use ***nvAgent*** to generate visualizations from natural language description. Upload .csv files and enter your requirement to generate visualizations simply.

We implement the interface in `web_vis`, and here is an demonstration.

<img src="https://github.com/Ouyangliangge/nvAgent/blob/main/assets/tinywow_web_70526330.gif" width="50%">


## 游꿀Updates

## 丘뙖잺Project Structure

This repo is organized as follows:

```txt
較럭core
|  較럭agents.py       # define three agents class
|  較럭api_config.py   # config API key and base
|  較럭chat_manager.py # manage the communication between agents
|  較럭const.py        # prompt templates
|  較럭llm.py          # config llm api call and write logs
|  較럭utils.py        # contains utils functions
較럭web_vis # the interface for nvAgent
|  較럭core
|  較럭templates
|  較럭app.py
較럭visEval # the evaluation framework
|  較럭check # contains different check aspects
|  較럭dataset.py # generate the dataset path mapping
|  較럭evaluate.py # evaluate the score of agent
較럭run_evaluate.py # evaluation script
較럭README.md
較럭requirements.txt
較럭visEval_dataset.zip # the dataset used for evaluation
```

## 丘멥tart



## 游꿣Evaluation

## 游눠Citation

## 游뿼Contributing
